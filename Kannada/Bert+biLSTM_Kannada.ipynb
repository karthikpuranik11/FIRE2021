{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert+biLSTM_Kannada.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikpuranik11/FIRE2021/blob/main/Kannada/Bert%2BbiLSTM_Kannada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQgS3U09Htd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3115c4f4-24b5-4adf-dc3c-e382ad3c1253"
      },
      "source": [
        "!pip install transformers==3.3.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.3.1\n",
            "  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñé                               | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |‚ñã                               | 20 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà                               | 30 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñé                              | 40 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñå                              | 51 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñâ                              | 61 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñè                             | 71 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñå                             | 81 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñâ                             | 92 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà                             | 102 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñç                            | 112 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñä                            | 122 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà                            | 133 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñé                           | 143 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñã                           | 153 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà                           | 163 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 174 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 184 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 194 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 204 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 215 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 225 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 235 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 245 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 256 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 266 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 276 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 286 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 296 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 307 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 317 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 327 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 337 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 348 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 358 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 368 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 378 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 389 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 399 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 409 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 419 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 430 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 440 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 450 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 460 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 471 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 481 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 491 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 501 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 512 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 522 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 532 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 542 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 552 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 563 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 573 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 583 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 593 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 604 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 614 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 624 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 634 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 645 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 655 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 665 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 675 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 686 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 696 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 706 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 716 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 727 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 737 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 747 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 757 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 768 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 778 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 788 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 798 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 808 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 819 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 829 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 839 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 849 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 860 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 870 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 880 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 890 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 901 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 911 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 921 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 931 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 942 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 952 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 962 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 972 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 983 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 993 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1.0 MB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1.0 MB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1.0 MB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1.0 MB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1.0 MB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1.1 MB 30.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0 MB 35.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (1.19.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BeHAb-BM9w1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "b269d0b5-77c8-4d45-ae87-b8d4e92540fa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train1=pd.read_csv('/content/kan_final.csv')\n",
        "train1['labels']=LabelEncoder().fit_transform(train1['category'])\n",
        "#train=train.drop(columns='label')\n",
        "train1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>trans</th>\n",
              "      <th>translate</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...</td>\n",
              "      <td>The progress of a country does not depend on i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...</td>\n",
              "      <td>Subscribe to our channel for Daily Tech update...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Super sar song</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç ‡≤∏‡≤∞‡≥ç ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç</td>\n",
              "      <td>Superb song\\n</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>‡≤ü‡≤ø‡≤ï‡≥ç‡≤ö‡≥ã‡≤ï‡≤∞‡≥ç‡≤∏‡≥ç ‡≤™‡≥Ü‡≤∞‡≥Ü‡≤Ç‡≤ü‡≥ç ‡≤∏‡≤ø‡≤ü‡≥ç‡≤Ø‡≥Ç‡≤∂‡≤®‡≥ç... ‡≤®‡≥ç‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ...</td>\n",
              "      <td>Tik Chockers' Parent Status: Who's watching ou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....</td>\n",
              "      <td>Positive</td>\n",
              "      <td>‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....</td>\n",
              "      <td>The song is very peppy.\\n</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6207</th>\n",
              "      <td>6207</td>\n",
              "      <td>6207</td>\n",
              "      <td>@A.R.W   tumbad tanhaji andhadhun aise bahot h...</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>@‡≤è.‡≤∞‡≥ç.‡≤é ‡≤§‡≤Ç‡≤¨‡≤¶‡≥ç ‡≤§‡≤Ç‡≤ú‡≤æ‡≤ú‡≤ø ‡≤Ö‡≤Ç‡≤ß‡≤ß‡≥Å‡≤®‡≥ç ‡≤ê‡≤∏‡≥ç‡≤°‡≥ç ‡≤¨‡≤π‡≤§‡≥ç ‡≤π‡≥à ‡≤™‡≥ç‡≤∞...</td>\n",
              "      <td>@ arra _ tambad, tanjaji, Andhadhun, aisd baat...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6208</th>\n",
              "      <td>6208</td>\n",
              "      <td>6208</td>\n",
              "      <td>‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç</td>\n",
              "      <td>(in Korean)\\n</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6209</th>\n",
              "      <td>6209</td>\n",
              "      <td>6209</td>\n",
              "      <td>Bro...nNeen este Roast madudru...China ne beku...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>‡≤¨‡≥ç‡≤∞‡≥ã...‡≤®‡≥ç‡≤Ø‡≥Ç‡≤®‡≥ç ‡≤é‡≤∏‡≥ç‡≤ü‡≥ç ‡≤∞‡≥ã‡≤∏‡≥ç‡≤ü‡≥ç ‡≤Æ‡≤æ‡≤°‡≥Å‡≤¶‡≥ç‡≤∞‡≥Å...‡≤ö‡≥Ä‡≤®‡≤æ ‡≤®‡≥á ...</td>\n",
              "      <td>\"\" \"Bro...\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6210</th>\n",
              "      <td>6210</td>\n",
              "      <td>6210</td>\n",
              "      <td>‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...</td>\n",
              "      <td>There is no dearth of talented people in our c...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6211</th>\n",
              "      <td>6211</td>\n",
              "      <td>6211</td>\n",
              "      <td>26 M Views</td>\n",
              "      <td>Mixed feelings</td>\n",
              "      <td>26 ‡≤é‡≤Æ‡≥ç ‡≤µ‡≥ç‡≤Ø‡≥Ç‡≤∏‡≥ç</td>\n",
              "      <td>26M Views\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6212 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...  labels\n",
              "0              0  ...       1\n",
              "1              1  ...       2\n",
              "2              2  ...       3\n",
              "3              3  ...       1\n",
              "4              4  ...       2\n",
              "...          ...  ...     ...\n",
              "6207        6207  ...       3\n",
              "6208        6208  ...       3\n",
              "6209        6209  ...       1\n",
              "6210        6210  ...       2\n",
              "6211        6211  ...       0\n",
              "\n",
              "[6212 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KYzltQvw0ZTN",
        "outputId": "7ccfce91-302c-4406-c23c-c4616db304b9"
      },
      "source": [
        "train=pd.DataFrame(columns=['labels','tweets'])\n",
        "train['labels']=train1['labels']\n",
        "train['tweets']=train1['text']\n",
        "train"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Super sar song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6207</th>\n",
              "      <td>3</td>\n",
              "      <td>@A.R.W   tumbad tanhaji andhadhun aise bahot h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6208</th>\n",
              "      <td>3</td>\n",
              "      <td>‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6209</th>\n",
              "      <td>1</td>\n",
              "      <td>Bro...nNeen este Roast madudru...China ne beku...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6210</th>\n",
              "      <td>2</td>\n",
              "      <td>‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6211</th>\n",
              "      <td>0</td>\n",
              "      <td>26 M Views</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6212 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      labels                                             tweets\n",
              "0          1  ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...\n",
              "1          2  ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...\n",
              "2          3                                     Super sar song\n",
              "3          1  Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...\n",
              "4          2                          Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....\n",
              "...      ...                                                ...\n",
              "6207       3  @A.R.W   tumbad tanhaji andhadhun aise bahot h...\n",
              "6208       3                  ‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç\n",
              "6209       1  Bro...nNeen este Roast madudru...China ne beku...\n",
              "6210       2  ‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...\n",
              "6211       0                                         26 M Views\n",
              "\n",
              "[6212 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dg7Uncl0tTb"
      },
      "source": [
        "train=train.dropna()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoAmYVC5Ldq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "17fdf202-9146-44f8-c672-eb0b26b74a4e"
      },
      "source": [
        "val=pd.read_csv('/content/kannada_sentiment_full_test_withlabels.tsv', sep=\"\\t\")\n",
        "print(val)\n",
        "#val['tweet']=val['text']\n",
        "#val=val.drop(columns=['Unnamed: 2','text'])\n",
        "val['labels']=LabelEncoder().fit_transform(val['category'])\n",
        "val['tweets']=val['text']\n",
        "val=val.drop(columns=['category','text'])\n",
        "val"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id                                               text        category\n",
            "0      Kan_1  ‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...        Positive\n",
            "1      Kan_2                                         Jai D Boss   unknown state\n",
            "2      Kan_3                                     Signature move     not-Kannada\n",
            "3      Kan_4                                     Super song bro        Positive\n",
            "4      Kan_5                        Wow  Super agi helidira sir        Positive\n",
            "..       ...                                                ...             ...\n",
            "763  Kan_764                                Thu thukali trailer   unknown state\n",
            "764  Kan_765  Siri gannadam galge haakbitallapa Thu  yaro ni...        Negative\n",
            "765  Kan_766  ‡≤®‡≤æ‡≤µ‡≥á‡≤®‡≤æ‡≤¶‡≤∞‡≥Å ‡≤∏‡≥ç‡≤µ‡≤æ‡≤¨‡≤ø‡≤Æ‡≤æ‡≤®‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤¨‡≤¶‡≥Å‡≤ï‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤ü‡≥ç‡≤ü‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å...        Positive\n",
            "766  Kan_767  ‡≤¶‡≤ø‡≤Ø‡≤æ ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≥ã‡≤∑‡≤ø‡≤Ø‡≤≤‡≥ç ‡≤Æ‡≥Ä‡≤°‡≤ø‡≤Ø‡≤æ ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤£‡≥ç‡≤§‡≤ø‡≤≤‡≥ç‡≤≤.n‡≤¶‡≤Ø‡≤µ‡≤ø...   unknown state\n",
            "767  Kan_768  magaluru kade kalsi avanannu .navu avanige mad...  Mixed feelings\n",
            "\n",
            "[768 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kan_1</td>\n",
              "      <td>2</td>\n",
              "      <td>‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kan_2</td>\n",
              "      <td>4</td>\n",
              "      <td>Jai D Boss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kan_3</td>\n",
              "      <td>3</td>\n",
              "      <td>Signature move</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kan_4</td>\n",
              "      <td>2</td>\n",
              "      <td>Super song bro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kan_5</td>\n",
              "      <td>2</td>\n",
              "      <td>Wow  Super agi helidira sir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>Kan_764</td>\n",
              "      <td>4</td>\n",
              "      <td>Thu thukali trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>Kan_765</td>\n",
              "      <td>1</td>\n",
              "      <td>Siri gannadam galge haakbitallapa Thu  yaro ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>Kan_766</td>\n",
              "      <td>2</td>\n",
              "      <td>‡≤®‡≤æ‡≤µ‡≥á‡≤®‡≤æ‡≤¶‡≤∞‡≥Å ‡≤∏‡≥ç‡≤µ‡≤æ‡≤¨‡≤ø‡≤Æ‡≤æ‡≤®‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤¨‡≤¶‡≥Å‡≤ï‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤ü‡≥ç‡≤ü‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>Kan_767</td>\n",
              "      <td>4</td>\n",
              "      <td>‡≤¶‡≤ø‡≤Ø‡≤æ ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≥ã‡≤∑‡≤ø‡≤Ø‡≤≤‡≥ç ‡≤Æ‡≥Ä‡≤°‡≤ø‡≤Ø‡≤æ ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤£‡≥ç‡≤§‡≤ø‡≤≤‡≥ç‡≤≤.n‡≤¶‡≤Ø‡≤µ‡≤ø...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>Kan_768</td>\n",
              "      <td>0</td>\n",
              "      <td>magaluru kade kalsi avanannu .navu avanige mad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  labels                                             tweets\n",
              "0      Kan_1       2  ‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...\n",
              "1      Kan_2       4                                         Jai D Boss\n",
              "2      Kan_3       3                                     Signature move\n",
              "3      Kan_4       2                                     Super song bro\n",
              "4      Kan_5       2                        Wow  Super agi helidira sir\n",
              "..       ...     ...                                                ...\n",
              "763  Kan_764       4                                Thu thukali trailer\n",
              "764  Kan_765       1  Siri gannadam galge haakbitallapa Thu  yaro ni...\n",
              "765  Kan_766       2  ‡≤®‡≤æ‡≤µ‡≥á‡≤®‡≤æ‡≤¶‡≤∞‡≥Å ‡≤∏‡≥ç‡≤µ‡≤æ‡≤¨‡≤ø‡≤Æ‡≤æ‡≤®‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤¨‡≤¶‡≥Å‡≤ï‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤ü‡≥ç‡≤ü‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å...\n",
              "766  Kan_767       4  ‡≤¶‡≤ø‡≤Ø‡≤æ ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≥ã‡≤∑‡≤ø‡≤Ø‡≤≤‡≥ç ‡≤Æ‡≥Ä‡≤°‡≤ø‡≤Ø‡≤æ ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤£‡≥ç‡≤§‡≤ø‡≤≤‡≥ç‡≤≤.n‡≤¶‡≤Ø‡≤µ‡≤ø...\n",
              "767  Kan_768       0  magaluru kade kalsi avanannu .navu avanige mad...\n",
              "\n",
              "[768 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS6rIZeEKma6"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class RFDataset(Dataset):\n",
        "  def __init__(self,text,label,tokenizer,max_len):\n",
        "    self.text = text\n",
        "    self.label = label\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "  \n",
        "  def __getitem__(self,item):\n",
        "    text = str(self.text[item])\n",
        "    label = self.label[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length = self.max_len,\n",
        "        return_token_type_ids = False,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask= True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'text' : text,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'label' : torch.tensor(label,dtype=torch.long)\n",
        "\n",
        "    }"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyLc0LX0M5U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1779a573-5846-488b-a75e-f74c242a55ad"
      },
      "source": [
        " \n",
        "print('Training set size:',train.shape)\n",
        "#Uncomment the next line when we have the test data\n",
        "#print('Testing set size:',test.shape)\n",
        "print('validation set size:',val.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: (6212, 2)\n",
            "validation set size: (768, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBHTeh4rO3Ri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa10171-e46a-4dd3-e66c-5e6ba173967a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                  np.unique(train.labels.values),\n",
        "                                                  train.labels.values)\n",
        "class_weights"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.16445993, 1.04579125, 0.44009919, 1.35633188, 1.74739803])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKS4d5sfRGOu"
      },
      "source": [
        "\n",
        "def create_data_loader(df,tokenizer,max_len,batch_size):\n",
        "  ds = RFDataset(\n",
        "      text = df.tweets.to_numpy(),\n",
        "      label = df.labels.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(ds,\n",
        "                    batch_size = batch_size,\n",
        "                    shuffle = True,\n",
        "                    num_workers=4)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkYcm1PRrGk"
      },
      "source": [
        "from transformers import XLNetTokenizer,XLNetModel,AdamW,get_linear_schedule_with_warmup,AutoModel,AutoTokenizer\n",
        "device = 'cuda'\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40efbyr8S0sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b0aba5-9ddd-41e8-92ba-7ce91d568cc9"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 128\n",
        "train_data_loader = create_data_loader(train,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val,tokenizer,MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdZHZ9UDTK1z"
      },
      "source": [
        "BERT_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOP_4eY031CX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class RFClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(RFClassifier, self).__init__()\n",
        "    self.auto = AutoModel.from_pretrained('bert-base-multilingual-uncased')\n",
        "    self.lstm = nn.LSTM(768, 256, batch_first=True,bidirectional=True)\n",
        "    self.linear = nn.Linear(256*2, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "    self.out = nn.Linear(128, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    sequence_output, pooled_output = self.auto(input_ids, \n",
        "               attention_mask=attention_mask)\n",
        "\n",
        "    # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "    lstm_output, (h,c) = self.lstm(sequence_output) ## extract the 1st token's embeddings\n",
        "    hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
        "    linear_output = self.linear(lstm_output[:,-1].view(-1,256*2)) ### assuming that you are only using the output of the last LSTM cell to perform classification\n",
        "\n",
        "    return linear_output"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Urr0ySUklT"
      },
      "source": [
        "model = RFClassifier(5)\n",
        "model = model.to(device)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5qaJSFdUtjo"
      },
      "source": [
        "EPOCHS = 5\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUMb1j_-VAPP"
      },
      "source": [
        "\n",
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        labels = data['label'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "            )\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs,labels)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vXGF1gAa6pf"
      },
      "source": [
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"label\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIJRHUwrgSDx"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb4NCM2lfQxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900d2b5b-054e-4d4c-f5ff-f1ae0772a0b2"
      },
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        " \n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        " \n",
        " \n",
        "  start_time = time.time()\n",
        "  train_acc,train_loss = train_epoch(\n",
        "      model,\n",
        "      train_data_loader,\n",
        "      loss_fn,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler,\n",
        "      len(train)\n",
        "  )\n",
        "   \n",
        "  \n",
        "  val_acc,val_loss = eval_model(\n",
        "      model,\n",
        "      val_data_loader,\n",
        "      loss_fn,\n",
        "      device,\n",
        "      len(val)\n",
        "  )\n",
        "  \n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'Train Loss {train_loss} accuracy {train_acc}')\n",
        "  print(f'Val Loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(),'bert-base-multilingual-uncased.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 37s\n",
            "Train Loss 1.5146682931826665 accuracy 0.49243399871217\n",
            "Val Loss 1.0961673632264137 accuracy 0.5833333333333333\n",
            "\n",
            "Epoch: 02 | Epoch Time: 2m 37s\n",
            "Train Loss 1.056522725789975 accuracy 0.6012556342562781\n",
            "Val Loss 0.9728925451636314 accuracy 0.64453125\n",
            "\n",
            "Epoch: 03 | Epoch Time: 2m 37s\n",
            "Train Loss 0.8801414660918407 accuracy 0.6819059884095299\n",
            "Val Loss 0.9799686844150225 accuracy 0.6184895833333333\n",
            "\n",
            "Epoch: 04 | Epoch Time: 2m 37s\n",
            "Train Loss 0.7489195573788423 accuracy 0.7361558274307791\n",
            "Val Loss 1.0210914239287376 accuracy 0.6315104166666666\n",
            "\n",
            "Epoch: 05 | Epoch Time: 2m 37s\n",
            "Train Loss 0.6645590521586247 accuracy 0.7707662588538313\n",
            "Val Loss 1.0684201667706172 accuracy 0.6184895833333333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TM3YTH3l37C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "3542b1a5-87f9-48be-9b04-4e3da11033c3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "#plt.ylim([0, 1]);"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f64c1f6a090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCB1-ymUoWtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e983c398-1b5d-4e70-ee16-b36f9c2e8817"
      },
      "source": [
        "val_acc, _ = eval_model(\n",
        "  model,\n",
        "  val_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(val) #Change it to test when you have the test results\n",
        ")\n",
        "val_acc.item()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6184895833333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAKW4Hz6obOV"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  sentence = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"label\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      sentence.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNIoCR3oqKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0d31eb-e352-4dde-d222-1637959da96a"
      },
      "source": [
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  val_data_loader\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLJOJO0Eorvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96054f31-c270-4828-c94c-69e180607bee"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test, y_pred,zero_division=0, digits=4))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2333    0.1077    0.1474        65\n",
            "           1     0.5875    0.5987    0.5931       157\n",
            "           2     0.6854    0.7513    0.7168       374\n",
            "           3     0.6404    0.6636    0.6518       110\n",
            "           4     0.3704    0.3226    0.3448        62\n",
            "\n",
            "    accuracy                         0.6185       768\n",
            "   macro avg     0.5034    0.4888    0.4908       768\n",
            "weighted avg     0.5952    0.6185    0.6040       768\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKH6ki1ORHDy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}